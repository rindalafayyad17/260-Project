---
title: "260 Project Description and Data collection"
output: html_document
---

### Background and Motivation

Over the course of our time as students here at the Harvard Chan School of Public Health, we will almost assuredly reach a point where we must assess our next professional move. For some, the answer may be continuing education via a doctoral program; however, others may join the workforce. 

Throughout this process, we will hopefully garner offers for positions from companies in varying cities. If we are in the fortunate circumstance to have to decide on competing offers, it would seem logical to compare the salaries across our offers. As educated members of Harvard University, we may decide that a more comprehensive comparison may be important. How far will my salary go in New York City? What is the cost of living in New Orleans? How much does an apartment cost, on average, in Des Moines, Iowa compared to Cambridge? Can I afford to go back to sunny Southern California?

The motivation of this project is to help create an interface, in the form of a shiny dashboard, to input salary offers and cities and comprehensively compare the offers in the form of summary statistics and visualizations --without the need of searching on Glassdoor,  LinkedIn, Zillow, and Yelp separately. 


### Project Objectives

The primary objective of the study is to put together salary data for various job titles in 50 US cities (similar to something you would see on Glassdoor) and additionally include the important cost of living measures such as apartment costs, meal costs, utilities, and other relevant information. The shiny dashboard is the pillar of the project; however, there are various other bits of information we can use to better understand these relationships. 

Visualizations are a key driver of our ability to make decisions with data. A powerful scatterplot can often convince someone of a decision in a way that a complex analysis may not be able to manage. As such, the goal will be to include visualizations that will help to assess the salaries needed for the cost of living across our 50 cities. Ideally, such visualization will be interactive and can be a separate tab or section of our dashboard, or simply included in our report. 

We are also interested in predicting the rent per month or apartment price per city based on other variables from our dataset. 

The end-goal is to create an app that people can use to compare different job offers in different cities, and make a decision based on the salary and the cities’ costs of living. We want to make it easier for people to choose the “best” job offer. 

### Data Source

Our data will be sourced from two distinct locations: numbeo.com and the Bureau of Labor Statistics (BLS). 
 
Numbeo offers data on the cost of living such as the cost of an inexpensive restaurant, the cost of milk, the cost of gas, the cost of childcare, average apartment cost (rent) for 1 bedroom inside the city, price per square foot to buy an apartment. This data will be and can be, gathered via web scraping. The URL changes in a uniform manner when looking at new cities so the URL can be easily manipulated to access our data and save it locally.  

BLS actually provides data on the average salaries of various job titles in metropolitan areas across the US. Since the data is not granular enough to be only to one particular city (i.e. Boston metro including Cambridge and neighboring cities,  not simply Boston proper), we will use the metropolitan salary data as a proxy. This data will be accessed directly from the site as separate files which will likely have to be bound together within R.


### Data collection

Let's start this project.

First we can upload the cost of living (COL) for Boston, MA. Would you look at that, it is pretty expensive to live in Boston. 

```{r, warning=FALSE, message=FALSE}
# read in packages
library(tidyverse)
library(stringr)
library(readr)
library(rvest)
library(lubridate)
library(pander)
library(httr)

```

```{r}
# boston only 
# eventually create a vector of cities, pass through url


url <- "https://www.numbeo.com/cost-of-living/in/Boston"

tab <- read_html(url) %>% html_nodes("table")

cost_table <- html_table(tab)[[2]]
cost_table


# cost of housing metrics
# cost per sq ft in city center
apartment_city <- cost_table[cost_table$Restaurants == "Apartment (1 bedroom) in City Centre",]

# cost per sq ft outside city center 
apartment_out <- cost_table[cost_table$Restaurants == "Apartment (1 bedroom) Outside of Centre",]

# average monthly salary 
salary <- cost_table[cost_table$Restaurants == "Average Monthly Net Salary (After Tax)",]


# cost of food metrics
# cost per inexpensive meal at restaurant
cheap_rest <- cost_table[cost_table$Restaurants == "Meal, Inexpensive Restaurant",]

# cost per two person dinner
exp_rest <- cost_table[cost_table$Restaurants == "Meal for 2 People, Mid-range Restaurant, Three-course",]


# cost of utilities metrics 
# basic utilities
basic_util <- cost_table[cost_table$Restaurants == "Basic (Electricity, Heating, Cooling, Water, Garbage) for 915 sq ft Apartment",]

# cost of wifi
wifi <- cost_table[cost_table$Restaurants == "Internet (60 Mbps or More, Unlimited Data, Cable/ADSL)",]


# create dataframe of the above
boston <- rbind(apartment_city,apartment_out, salary, cheap_rest, exp_rest, basic_util, wifi) %>% 
  rename(metrics = Restaurants, 
         price = Edit) %>% 
  select(metrics, price)

# make cleanup prices a function
# removes money signs, commas and whitespaces 
cln_price <- function(citydata){
  citydata <- citydata %>% 
    mutate(price = str_replace(price, "\\$", "")) %>%
    mutate(price = str_replace(price, "\\,", "")) %>% 
    mutate(price = str_trim(price)) %>% 
    mutate(price = as.numeric(price, digits = 7))
  return(citydata)
}

#pass our boston data to be cleaned
boston <- cln_price(boston)

head(boston)

# add a column with city name, will need to be made into a function
boston <- boston %>% 
  mutate(city = "boston") 

addcity <- function(citydata){
  citydata <- citydata
}

# finally just to see our result  
boston %>%  pander()
```

Boston is neat to know, but what about other cities? After all, we will be job hunting soon and would like to know what it is going to cost us to live in these new cities. 

Scraping the data responsibly by using the slowly() function in the httr package, we can get data for the following 50 cities in the United States. These cities were selected from a list of top/most populated cities in the US. 

An important note is that we are only looking at certain rows here from the original numbeo dataset, this helps to keep the appearance of our data tidy as well as keep the cleaning function simple. We can choose to add any rows of interest very simply below if we wish to include something like the price of milk, eggs, childcare, etc. 

```{r}
## --> denotes lines that should be run but will not run to not swarm the server 



# testing
alldata <- data.frame()
# create  cities list
cities_list <- c("Los-Angeles", "New-York", "Chicago", "Houston", "Phoenix", "Philadelphia", "San-Antonio", "San-Diego", "Dallas", "San-Jose", "Austin", "Jacksonville", "Fort-Worth", "Columbus", "Charlotte", "San-Francisco", "Indianapolis", "Seattle", "Denver", "Boston", "El-Paso", "Washington", "Nashville", "Detroit", "Oklahoma-City", "Portland", "Las-Vegas", "Memphis", "Louisville", "Baltimore", "Milwaukee", "Albuquerque", "Tucson", "Fresno", "Mesa", "Sacramento", "Atlanta", "Kansas-City", "Colorado-Springs", "Omaha", "Raleigh", "Miami", "Long-Beach", "Virginia-Beach", "Oakland", "Minneapolis", "Tulsa", "Tampa", "Arlington", "New-Orleans" )


#############################################################
# Functions
############################################################

#time delayed get
throttled_read_html <- slowly(~ read_html(.),
                    rate = rate_delay(0.5))

 make_df <- function(cities){
   alldata <- data.frame()
   for(i in 1: length(cities)){
    # want to end up with length of cities cost tables
    # webscrape
     url <- paste0("https://www.numbeo.com/cost-of-living/in/", cities[i])
     tab <- throttled_read_html(url) %>% html_nodes("table")
    # create inital cost of living table
     cost_table <- html_table(tab)[[2]]
    # want to add column of city = city name
    # rename some columns
    # select columns (basically exclude range column)
     cost_table <- cost_table %>% 
       mutate(city = as.character(cities[i])) %>% 
       rename(metrics = Restaurants, price = Edit) %>% 
       select(city,metrics,price)
    # select important rows
    # cost per sq ft in city center
     apartment_city <- cost_table[cost_table$metrics == "Apartment (1 bedroom) in City Centre",]
    # cost per sq ft outside city center 
     apartment_out <- cost_table[cost_table$metrics == "Apartment (1 bedroom) Outside of Centre",]
    # average monthly salary 
     salary <- cost_table[cost_table$metrics == "Average Monthly Net Salary (After Tax)",]
    # cost of food metrics
    # cost per inexpensive meal at restaurant
     cheap_rest <- cost_table[cost_table$metrics == "Meal, Inexpensive Restaurant",]
    # cost per two person dinner
     exp_rest <- cost_table[cost_table$metrics == "Meal for 2 People, Mid-range Restaurant, Three-course",]
    # cost of utilities metrics 
    # basic utilities
     basic_util <- cost_table[cost_table$metrics == "Basic (Electricity, Heating, Cooling, Water, Garbage) for 915 sq ft Apartment",]
    # cost of wifi
     wifi <- cost_table[cost_table$metrics == "Internet (60 Mbps or More, Unlimited Data, Cable/ADSL)",]
    # create dataframe of the above
    # will change for every city
     citydata <- rbind(apartment_city,apartment_out, salary, cheap_rest, exp_rest, basic_util, wifi)
    # bind new cost table to previous cost tables 
     alldata <- bind_rows(alldata,citydata)
   }
   return(alldata)
   }

# Clean data function
cln_price <- function(citydata){
  citydata <- citydata %>% 
    # replace various things and trim
    mutate(price = str_replace(price, "\\$", "")) %>%
    mutate(price = str_replace(price, "\\,", "")) %>% 
    mutate(price = str_trim(price)) %>% 
    mutate(price = as.numeric(price, digits = 7)) %>% 
    mutate(city = str_replace(city, "\\-", " "))
  return(citydata)
}


#################################
# Data collecting and cleaning
################################

## mydata <- make_df(cities_list)
## mydata <- cln_price(mydata)
## write_csv(mydata, "/mycsv.csv")




```


Now we will look at the salary data.
```{r}
library(tidyverse)
library(dplyr)
library(stringr)

dat <- read.csv(file = "wages.csv", header = TRUE)

sub <- dat %>% select(AREA_TITLE, OCC_TITLE, H_MEAN, A_MEAN)

sub <- sub %>% separate(AREA_TITLE, c("City", "State"), sep = ",") #separating city and states into two different columns

cities <- c("Los Angeles", "New York", "Chicago", "Houston", "Phoenix", "Philadelphia", "San Antonio", "San Diego", "Dallas", "San Jose", "Austin", "Jacksonville", "Fort Worth", "Columbus", "Charlotte", "San Francisco", "Indianapolis", "Seattle", "Denver", "Boston", "El Paso", "Washington", "Nashville", "Detroit", "Oklahoma City", "Portland", "Las Vegas", "Memphis", "Louisville", "Baltimore", "Milwaukee", "Albuquerque", "Tucson", "Fresno", "Mesa", "Sacramento", "Atlanta", "Kansas City", "Colorado Springs", "Omaha", "Raleigh", "Miami", "Long Beach", "Virginia Beach", "Oakland", "Minneapolis", "Tulsa", "Tampa", "Arlington", "New Orleans" )

sep_cities <- sub %>% separate(City, c("City1", "City2", "City3"), sep = "-") #separating the entries that include multiple city names into different columns

df1 <- sep_cities %>% 
  select(- c("City2", "City3"))
colnames(df1)[1] <- "City"
#creating a new data frame with the first city column only

df2 <- sep_cities %>%
  select(-c("City1", "City3"))
colnames(df2)[1] <- "City"
#creating a new data frame with the second city column only

df3 <- sep_cities %>%
  select(-c("City1", "City2"))
colnames(df3)[1] <- "City"
#creating a new data frame with the third city column only

one_city <- rbind(df1, df2, df3) #stacking the three data frames above on top of each other to get only one column for the cities where each row corresponds to one city only 

one_city$City[one_city$City == "Louisville/Jefferson County"] <- "Louisville" #renaming this city entry to Louisville only

final <- one_city %>% filter(City %in% cities) %>% select(-State) #final data frame with city only without the state

length(unique(final$City))
not_included <- ! (cities %in% final$City)
cities[not_included]
#all the cities are included in the final dataset

colnames(final) <- c("City", "Occupation", "Hourly Wage", "Annual Wage") #renaming the columns

final$`Hourly Wage`[final$`Hourly Wage` == "*"] <- NA
final$`Annual Wage`[final$`Annual Wage` == "*"] <- NA
final$`Hourly Wage`[final$`Hourly Wage` == "#"] <- ">100"
final$`Annual Wage`[final$`Annual Wage` == "#"] <- ">208000"



```

```{r}

#deleting repeated Occupations

final <- final %>% arrange(City, Occupation) #arranging the dataset by city then by occupation

mat <- matrix(ncol = 4, nrow = 0) #creating an empty matrix where I will store unique rows
no_repeats <- as.data.frame(mat)
colnames(no_repeats) <- c("City", "Occupation", "Hourly Wage", "Annual Wage")

for (i in 1:nrow(final)){
  if (final$Occupation[i] != final$Occupation[min(nrow(final),i+1)]){
    no_repeats[i,] <- final[i,]
    
  }
}
#looping over the rows of the data frame and extracting the rows with unique city and occupation

no_repeats <- no_repeats %>% filter(!(City %in% NA)) #removing all NAs that were created.

# save this file locally
#write.csv(no_repeats,"C:/Users/Rindala/Desktop/Harvard/FALL 2021/BST 260/260-Project\\wages_norepeats.csv", row.names = FALSE)
```

Now we want to remove the "All Other" from the Occupations
```{r}
cleaned_occupations <- no_repeats %>% 
  mutate_at("Occupation", str_replace, ", All Other", "")

#save this file locally
#write.csv(cleaned_occupations,"C:/Users/Rindala/Desktop/Harvard/FALL 2021/BST 260/260-Project/saavy_salary\\cleaned_occupations.csv", row.names = FALSE)

```


Previously, we selected specific elements from numbeo of interest. However, below we will get all elements from numbeo related to cost of living. This will be cleaned and stored locally. However, it will also exist as full_col_data.csv within the project folder. 

```{r}
alldata <- data.frame()

cities_list <- c("Los-Angeles", "New-York", "Chicago", "Houston", "Phoenix", "Philadelphia", "San-Antonio", "San-Diego", "Dallas", "San-Jose", "Austin", "Jacksonville", "Fort-Worth", "Columbus", "Charlotte", "San-Francisco", "Indianapolis", "Seattle", "Denver", "Boston", "El-Paso", "Washington", "Nashville", "Detroit", "Oklahoma-City", "Portland", "Las-Vegas", "Memphis", "Louisville", "Baltimore", "Milwaukee", "Albuquerque", "Tucson", "Fresno", "Mesa", "Sacramento", "Atlanta", "Kansas-City", "Colorado-Springs", "Omaha", "Raleigh", "Miami", "Long-Beach", "Virginia-Beach", "Oakland", "Minneapolis", "Tulsa", "Tampa", "Arlington", "New-Orleans" )

#time delayed get
throttled_read_html <- slowly(~ read_html(.),
                    rate = rate_delay(0.5))

 make_df <- function(cities){
   alldata <- data.frame()
   for(i in 1: length(cities)){
    # want to end up with length of cities cost tables
    # webscrape
     url <- paste0("https://www.numbeo.com/cost-of-living/in/", cities[i])
     tab <- throttled_read_html(url) %>% html_nodes("table")
    # create inital cost of living table
     cost_table <- html_table(tab)[[2]]
    # want to add column of city = city name
    # rename some columns
    # select columns (basically exclude range column)
     cost_table <- cost_table %>% 
       mutate(city = as.character(cities[i])) %>% 
       rename(metrics = Restaurants, price = Edit) %>% 
       select(city,metrics,price)
      alldata <- bind_rows(alldata,cost_table)
   }
   return(alldata)
   }



# make  cleaning function which first removed any rows where the price column == edit
cln_full <- function(alldata){
  alldata = alldata %>% 
    # remove all rows where price is edit, this is excess from scraping
  filter(price != "Edit") %>% 
    # trim and replcae
  mutate(price = str_replace(price, "\\$", "")) %>%
    mutate(price = str_replace(price, "\\,", "")) %>% 
    mutate(price = str_trim(price)) %>% 
    mutate(price = as.numeric(price, digits = 7)) %>% 
    mutate(city = str_replace(city, "\\-", " "))
  return(alldata)
}



# this is df of all values from numbeo for 50 cities
# final datasets
############################################
# Do not run below since will just bother the server for numbeo unneccessarily
# files included in folder and within shiny app 
#############################################


#mydata <- make_df(cities_list)
#full_col_data <- cln_full(mydata)

# write this csv locally and upload it to the shiny server , as well as to this project file
#write_csv(full_col_data, "C:/Users/herrerad/Documents/full_col_data.csv")
```







