---
title: "260 Project Data collection and cleaning"
output: html_document
---

### Data collection

Let's start this project.

First we can upload the cost of living (COL) for Boston, MA. Would you look at that, it is pretty expensive to live in Boston. 

```{r, warning=FALSE, message=FALSE}
# read in packages
library(tidyverse)
library(stringr)
library(readr)
library(rvest)
library(lubridate)
library(pander)
library(httr)

```

```{r}
# boston only 
# eventually create a vector of cities, pass through url


url <- "https://www.numbeo.com/cost-of-living/in/Boston"

tab <- read_html(url) %>% html_nodes("table")

cost_table <- html_table(tab)[[2]]
cost_table


# cost of housing metrics
# cost per sq ft in city center
apartment_city <- cost_table[cost_table$Restaurants == "Apartment (1 bedroom) in City Centre",]

# cost per sq ft outside city center 
apartment_out <- cost_table[cost_table$Restaurants == "Apartment (1 bedroom) Outside of Centre",]

# average monthly salary 
salary <- cost_table[cost_table$Restaurants == "Average Monthly Net Salary (After Tax)",]


# cost of food metrics
# cost per inexpensive meal at restaurant
cheap_rest <- cost_table[cost_table$Restaurants == "Meal, Inexpensive Restaurant",]

# cost per two person dinner
exp_rest <- cost_table[cost_table$Restaurants == "Meal for 2 People, Mid-range Restaurant, Three-course",]


# cost of utilities metrics 
# basic utilities
basic_util <- cost_table[cost_table$Restaurants == "Basic (Electricity, Heating, Cooling, Water, Garbage) for 915 sq ft Apartment",]

# cost of wifi
wifi <- cost_table[cost_table$Restaurants == "Internet (60 Mbps or More, Unlimited Data, Cable/ADSL)",]


# create dataframe of the above
boston <- rbind(apartment_city,apartment_out, salary, cheap_rest, exp_rest, basic_util, wifi) %>% 
  rename(metrics = Restaurants, 
         price = Edit) %>% 
  select(metrics, price)

# make cleanup prices a function
# removes money signs, commas and whitespaces 
cln_price <- function(citydata){
  citydata <- citydata %>% 
    mutate(price = str_replace(price, "\\$", "")) %>%
    mutate(price = str_replace(price, "\\,", "")) %>% 
    mutate(price = str_trim(price)) %>% 
    mutate(price = as.numeric(price, digits = 7))
  return(citydata)
}

#pass our boston data to be cleaned
boston <- cln_price(boston)

head(boston)

# add a column with city name, will need to be made into a function
boston <- boston %>% 
  mutate(city = "boston") 

addcity <- function(citydata){
  citydata <- citydata
}

# finally just to see our result  
boston %>%  pander()
```

Boston is neat to know, but what about other cities? After all, we will be job hunting soon and would like to know what it is going to cost us to live in these new cities. 

Scraping the data responsibly by using the slowly() function in the httr package, we can get data for the following 50 cities in the United States. These cities were selected from a list of top/most populated cities in the US. 

An important note is that we are only looking at certain rows here from the original numbeo dataset, this helps to keep the appearance of our data tidy as well as keep the cleaning function simple. We can choose to add any rows of interest very simply below if we wish to include something like the price of milk, eggs, childcare, etc. 

```{r}
## --> denotes lines that should be run but will not run to not swarm the server 



# testing
alldata <- data.frame()
# create  cities list
cities_list <- c("Los-Angeles", "New-York", "Chicago", "Houston", "Phoenix", "Philadelphia", "San-Antonio", "San-Diego", "Dallas", "San-Jose", "Austin", "Jacksonville", "Fort-Worth", "Columbus", "Charlotte", "San-Francisco", "Indianapolis", "Seattle", "Denver", "Boston", "El-Paso", "Washington", "Nashville", "Detroit", "Oklahoma-City", "Portland", "Las-Vegas", "Memphis", "Louisville", "Baltimore", "Milwaukee", "Albuquerque", "Tucson", "Fresno", "Mesa", "Sacramento", "Atlanta", "Kansas-City", "Colorado-Springs", "Omaha", "Raleigh", "Miami", "Long-Beach", "Virginia-Beach", "Oakland", "Minneapolis", "Tulsa", "Tampa", "Arlington", "New-Orleans" )


#############################################################
# Functions
############################################################

#time delayed get
throttled_read_html <- slowly(~ read_html(.),
                    rate = rate_delay(0.5))

 make_df <- function(cities){
   alldata <- data.frame()
   for(i in 1: length(cities)){
    # want to end up with length of cities cost tables
    # webscrape
     url <- paste0("https://www.numbeo.com/cost-of-living/in/", cities[i])
     tab <- throttled_read_html(url) %>% html_nodes("table")
    # create inital cost of living table
     cost_table <- html_table(tab)[[2]]
    # want to add column of city = city name
    # rename some columns
    # select columns (basically exclude range column)
     cost_table <- cost_table %>% 
       mutate(city = as.character(cities[i])) %>% 
       rename(metrics = Restaurants, price = Edit) %>% 
       select(city,metrics,price)
    # select important rows
    # cost per sq ft in city center
     apartment_city <- cost_table[cost_table$metrics == "Apartment (1 bedroom) in City Centre",]
    # cost per sq ft outside city center 
     apartment_out <- cost_table[cost_table$metrics == "Apartment (1 bedroom) Outside of Centre",]
    # average monthly salary 
     salary <- cost_table[cost_table$metrics == "Average Monthly Net Salary (After Tax)",]
    # cost of food metrics
    # cost per inexpensive meal at restaurant
     cheap_rest <- cost_table[cost_table$metrics == "Meal, Inexpensive Restaurant",]
    # cost per two person dinner
     exp_rest <- cost_table[cost_table$metrics == "Meal for 2 People, Mid-range Restaurant, Three-course",]
    # cost of utilities metrics 
    # basic utilities
     basic_util <- cost_table[cost_table$metrics == "Basic (Electricity, Heating, Cooling, Water, Garbage) for 915 sq ft Apartment",]
    # cost of wifi
     wifi <- cost_table[cost_table$metrics == "Internet (60 Mbps or More, Unlimited Data, Cable/ADSL)",]
    # create dataframe of the above
    # will change for every city
     citydata <- rbind(apartment_city,apartment_out, salary, cheap_rest, exp_rest, basic_util, wifi)
    # bind new cost table to previous cost tables 
     alldata <- bind_rows(alldata,citydata)
   }
   return(alldata)
   }

# Clean data function
cln_price <- function(citydata){
  citydata <- citydata %>% 
    # replace various things and trim
    mutate(price = str_replace(price, "\\$", "")) %>%
    mutate(price = str_replace(price, "\\,", "")) %>% 
    mutate(price = str_trim(price)) %>% 
    mutate(price = as.numeric(price, digits = 7)) %>% 
    mutate(city = str_replace(city, "\\-", " "))
  return(citydata)
}


#################################
# Data collecting and cleaning
################################

## mydata <- make_df(cities_list)
## mydata <- cln_price(mydata)
## write_csv(mydata, "/mycsv.csv")




```


Now we will look at the salary data.
```{r}
library(tidyverse)
library(dplyr)
library(stringr)

dat <- read.csv(file = "wages.csv", header = TRUE)

sub <- dat %>% select(AREA_TITLE, OCC_TITLE, H_MEAN, A_MEAN)

sub <- sub %>% separate(AREA_TITLE, c("City", "State"), sep = ",") #separating city and states into two different columns

cities <- c("Los Angeles", "New York", "Chicago", "Houston", "Phoenix", "Philadelphia", "San Antonio", "San Diego", "Dallas", "San Jose", "Austin", "Jacksonville", "Fort Worth", "Columbus", "Charlotte", "San Francisco", "Indianapolis", "Seattle", "Denver", "Boston", "El Paso", "Washington", "Nashville", "Detroit", "Oklahoma City", "Portland", "Las Vegas", "Memphis", "Louisville", "Baltimore", "Milwaukee", "Albuquerque", "Tucson", "Fresno", "Mesa", "Sacramento", "Atlanta", "Kansas City", "Colorado Springs", "Omaha", "Raleigh", "Miami", "Long Beach", "Virginia Beach", "Oakland", "Minneapolis", "Tulsa", "Tampa", "Arlington", "New Orleans" )

sep_cities <- sub %>% separate(City, c("City1", "City2", "City3"), sep = "-") #separating the entries that include multiple city names into different columns

df1 <- sep_cities %>% 
  select(- c("City2", "City3"))
colnames(df1)[1] <- "City"
#creating a new data frame with the first city column only

df2 <- sep_cities %>%
  select(-c("City1", "City3"))
colnames(df2)[1] <- "City"
#creating a new data frame with the second city column only

df3 <- sep_cities %>%
  select(-c("City1", "City2"))
colnames(df3)[1] <- "City"
#creating a new data frame with the third city column only

one_city <- rbind(df1, df2, df3) #stacking the three data frames above on top of each other to get only one column for the cities where each row corresponds to one city only 

one_city$City[one_city$City == "Louisville/Jefferson County"] <- "Louisville" #renaming this city entry to Louisville only

final <- one_city %>% filter(City %in% cities) %>% select(-State) #final data frame with city only without the state

length(unique(final$City))
not_included <- ! (cities %in% final$City)
cities[not_included]
#all the cities are included in the final dataset

colnames(final) <- c("City", "Occupation", "Hourly Wage", "Annual Wage") #renaming the columns

final$`Hourly Wage`[final$`Hourly Wage` == "*"] <- NA
final$`Annual Wage`[final$`Annual Wage` == "*"] <- NA
final$`Hourly Wage`[final$`Hourly Wage` == "#"] <- ">100"
final$`Annual Wage`[final$`Annual Wage` == "#"] <- ">208000"



```

```{r}

#deleting repeated Occupations

final <- final %>% arrange(City, Occupation) #arranging the dataset by city then by occupation

mat <- matrix(ncol = 4, nrow = 0) #creating an empty matrix where I will store unique rows
no_repeats <- as.data.frame(mat)
colnames(no_repeats) <- c("City", "Occupation", "Hourly Wage", "Annual Wage")

for (i in 1:nrow(final)){
  if (final$Occupation[i] != final$Occupation[min(nrow(final),i+1)]){
    no_repeats[i,] <- final[i,]
    
  }
}
#looping over the rows of the data frame and extracting the rows with unique city and occupation

no_repeats <- no_repeats %>% filter(!(City %in% NA)) #removing all NAs that were created.

# save this file locally
#write.csv(no_repeats,"C:/Users/Rindala/Desktop/Harvard/FALL 2021/BST 260/260-Project\\wages_norepeats.csv", row.names = FALSE)
```

Now we want to remove the "All Other" from the Occupations
```{r}
cleaned_occupations <- no_repeats %>% 
  mutate_at("Occupation", str_replace, ", All Other", "")

#save this file locally
#write.csv(cleaned_occupations,"C:/Users/Rindala/Desktop/Harvard/FALL 2021/BST 260/260-Project/saavy_salary\\cleaned_occupations.csv", row.names = FALSE)

```


Previously, we selected specific elements from numbeo of interest. However, below we will get all elements from numbeo related to cost of living. This will be cleaned and stored locally. However, it will also exist as full_col_data.csv within the project folder. 

```{r}
alldata <- data.frame()

cities_list <- c("Los-Angeles", "New-York", "Chicago", "Houston", "Phoenix", "Philadelphia", "San-Antonio", "San-Diego", "Dallas", "San-Jose", "Austin", "Jacksonville", "Fort-Worth", "Columbus", "Charlotte", "San-Francisco", "Indianapolis", "Seattle", "Denver", "Boston", "El-Paso", "Washington", "Nashville", "Detroit", "Oklahoma-City", "Portland", "Las-Vegas", "Memphis", "Louisville", "Baltimore", "Milwaukee", "Albuquerque", "Tucson", "Fresno", "Mesa", "Sacramento", "Atlanta", "Kansas-City", "Colorado-Springs", "Omaha", "Raleigh", "Miami", "Long-Beach", "Virginia-Beach", "Oakland", "Minneapolis", "Tulsa", "Tampa", "Arlington", "New-Orleans" )

#time delayed get
throttled_read_html <- slowly(~ read_html(.),
                    rate = rate_delay(0.5))

 make_df <- function(cities){
   alldata <- data.frame()
   for(i in 1: length(cities)){
    # want to end up with length of cities cost tables
    # webscrape
     url <- paste0("https://www.numbeo.com/cost-of-living/in/", cities[i])
     tab <- throttled_read_html(url) %>% html_nodes("table")
    # create inital cost of living table
     cost_table <- html_table(tab)[[2]]
    # want to add column of city = city name
    # rename some columns
    # select columns (basically exclude range column)
     cost_table <- cost_table %>% 
       mutate(city = as.character(cities[i])) %>% 
       rename(metrics = Restaurants, price = Edit) %>% 
       select(city,metrics,price)
      alldata <- bind_rows(alldata,cost_table)
   }
   return(alldata)
   }



# make  cleaning function which first removed any rows where the price column == edit
cln_full <- function(alldata){
  alldata = alldata %>% 
    # remove all rows where price is edit, this is excess from scraping
  filter(price != "Edit") %>% 
    # trim and replcae
  mutate(price = str_replace(price, "\\$", "")) %>%
    mutate(price = str_replace(price, "\\,", "")) %>% 
    mutate(price = str_trim(price)) %>% 
    mutate(price = as.numeric(price, digits = 7)) %>% 
    mutate(city = str_replace(city, "\\-", " "))
  return(alldata)
}



# this is df of all values from numbeo for 50 cities
# final datasets
############################################
# Do not run below since will just bother the server for numbeo unneccessarily
# files included in folder and within shiny app 
#############################################


#mydata <- make_df(cities_list)
#full_col_data <- cln_full(mydata)

# write this csv locally and upload it to the shiny server , as well as to this project file
#write_csv(full_col_data, "C:/Users/herrerad/Documents/full_col_data.csv")
```







